{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaaiPPbYIYO6"
   },
   "source": [
    "# Topic: Comparative Analysis of BERT and RoBERTa for Sentiment Classification of COVID-19 Tweets: Optimising Transfer Learning Strategies for Crisis Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwzUWAusJacc"
   },
   "source": [
    "### This work investigates the comparative performance of fine-tuned BERT and RoBERTa models for sentiment analysis on COVID-19 tweets. It explores the impact of pre-processing techniques, specifically focusing on the removal of URLs, trailing hashtags, and punctuation, to evaluate their influence on model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "97vZ3ODYcJuD",
    "outputId": "09d7960b-7ef7-4ee6-f5d1-cb02f5532cc9"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Data Balancing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Machine Learning Models (Naive Bayes)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformers (BERT & RoBERTa)\n",
    "from transformers import BertTokenizerFast, TFBertModel\n",
    "from transformers import RobertaTokenizerFast, TFRobertaModel\n",
    "\n",
    "# Deep Learning (Keras)\n",
    "from tensorflow import keras\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Reproducibility & Visualization Setup\n",
    "seed = 42\n",
    "\n",
    "# Set a Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()\n",
    "\n",
    "# Set a valid Matplotlib style from the available list\n",
    "plt.style.use(\"ggplot\")  # Replace \"ggplot\" with any valid style from plt.style.available\n",
    "\n",
    "# Additional configuration\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRLSNbV1rAWa"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmjyTuWIrGmV"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Corona_train.csv',encoding='ISO-8859-1')\n",
    "df_test = pd.read_csv('Corona_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4Yp-D54WrV1z",
    "outputId": "919af745-1090-4033-f68a-2abe0e3d12e5"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "sNK6-d9DQ2yw",
    "outputId": "035e334b-b326-4f55-fb82-8a899abc01f1"
   },
   "outputs": [],
   "source": [
    "#Sentiment Distribution\n",
    "df.groupby('Sentiment').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2eu09n5kMBE",
    "outputId": "352b5cd5-800c-41be-8eb5-c88e1bcf5c81"
   },
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqXTvoIIrZlK",
    "outputId": "b06ca32d-66fb-4d5b-d75e-cb885e51b8fc"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBLi4njbrlxc"
   },
   "outputs": [],
   "source": [
    "df['TweetAt'] = pd.to_datetime(df['TweetAt'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpWI_uwSryzN"
   },
   "source": [
    "# Check for Duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQtjUQI4r541"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='OriginalTweet',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o99KpyzsC7r",
    "outputId": "48395bd5-13f1-4982-d656-3d3427701c62"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7O9XdFCschz"
   },
   "source": [
    "# Tweets Count by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jb5p3vYJshB-"
   },
   "outputs": [],
   "source": [
    "tweets_per_day = df['TweetAt'].dt.strftime('%m-%d').value_counts().sort_index().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "QyCN5OuHsmo1",
    "outputId": "c3ba133d-6f32-46a2-bdb3-1c3d620b1375"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "ax = sns.barplot(\n",
    "    x='TweetAt',  # Use the correct column name for dates\n",
    "    y='counts', data=tweets_per_day, edgecolor='black', ci=None, palette='Blues_r'  # Changed errorbar to ci\n",
    ")\n",
    "plt.title('Tweets count by date')\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgsCMEJOzVdB"
   },
   "source": [
    "# Tweets per country and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-mnMixjx2z9"
   },
   "outputs": [],
   "source": [
    "tweets_per_country = df['Location'].value_counts().loc[lambda x : x > 100].reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "ImOCIvcPzfKT",
    "outputId": "e66dd681-5576-4d60-d3ae-6c56cbb13926"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ax = sns.barplot(x='Location', y='counts', data=tweets_per_country, edgecolor='black', errorbar=('ci', False), palette='Spectral')\n",
    "plt.title('Tweets count by country')\n",
    "plt.xticks(rotation=70)  # Rotate x-axis labels for better readability\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "FrvGiPQS3MBS",
    "outputId": "a5598b58-d734-4fbb-a5cc-f4ac85c3b004"
   },
   "outputs": [],
   "source": [
    "#Distribution of Sentiments Over Time\n",
    "# Ensure 'TweetAt' is in datetime format\n",
    "df['TweetAt'] = pd.to_datetime(df['TweetAt'])\n",
    "\n",
    "# Group by date and sentiment, count occurrences\n",
    "sentiment_over_time = df.groupby([df['TweetAt'].dt.date, 'Sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate percentage\n",
    "sentiment_over_time_pct = sentiment_over_time.div(sentiment_over_time.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "for column in sentiment_over_time_pct.columns:\n",
    "    plt.plot(sentiment_over_time_pct.index, sentiment_over_time_pct[column], label=column, linewidth=2)\n",
    "\n",
    "plt.title('Distribution of Sentiments Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Percentage of Tweets', fontsize=12)\n",
    "plt.legend(title='Sentiment', title_fontsize='13', fontsize='11')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Rotate and align the tick labels so they look better\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Use a serif font for better readability\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Add a tight layout to prevent clipping of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q1UNhKZ1AOL"
   },
   "source": [
    "# Data Preprocessing for Sentiment Analysis\n",
    "To focus on the sentiment analysis task, we will perform targeted data cleaning on the raw tweet text within the provided DataFrame. This process will involve selecting the relevant columns: 'Originaltweet' containing the raw tweets and 'Sentiment' representing the target sentiment labels. This selection streamlines the analysis by focusing on the essential information for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQA4pDKq0LYI"
   },
   "outputs": [],
   "source": [
    "df = df[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SnElg851lTp"
   },
   "outputs": [],
   "source": [
    "df_test = df_test[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8rFu2SP19lE"
   },
   "outputs": [],
   "source": [
    "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
    "\n",
    "def strip_emoji(text):\n",
    "    \"\"\"Removes emojis from a string using a basic regular expression (may not capture all emojis).\"\"\"\n",
    "    # This is a simplified approach, more comprehensive emoji removal might require external libraries\n",
    "    emojis_pattern = r\"[^a-zA-Z0-9\\s_]+\"\n",
    "    return re.sub(emojis_pattern, \"\", text)\n",
    "\n",
    "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
    "def strip_all_entities(text):\n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_346nyaf5VBR"
   },
   "outputs": [],
   "source": [
    "# Define functions for text pre-processing (replace with your actual function definitions)\n",
    "def remove_mult_spaces(text):\n",
    "  # Function to remove multiple spaces and replace with a single space\n",
    "  return ' '.join(text.split())\n",
    "\n",
    "def filter_chars(text):\n",
    "  # Function to remove specific characters (adjust as needed)\n",
    "  return text\n",
    "\n",
    "def clean_hashtags(text):\n",
    "  # Function to clean hashtags (adjust as needed)\n",
    "  return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "  # Function to remove entities like mentions and URLs (adjust as needed)\n",
    "  text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "  text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "\n",
    "  # Import string module in cell 25\n",
    "  import string\n",
    "  banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "  table = str.maketrans('', '', banned_list)\n",
    "  text = text.translate(table)\n",
    "\n",
    "  return text\n",
    "\n",
    "def strip_emoji(text):\n",
    "  # Function to remove emojis (adjust as needed)\n",
    "  return text\n",
    "\n",
    "# Process main dataframe\n",
    "texts_new = []\n",
    "for t in df.OriginalTweet:\n",
    "    texts_new.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))\n",
    "\n",
    "# Process test dataframe\n",
    "texts_new_test = []\n",
    "for t in df_test.OriginalTweet:\n",
    "    texts_new_test.append(remove_mult_spaces(filter_chars(clean_hashtags(strip_all_entities(strip_emoji(t))))))\n",
    "\n",
    "# Assign processed text to new columns\n",
    "df['text_clean'] = texts_new\n",
    "df_test['text_clean'] = texts_new_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX-PQTRS6nXm"
   },
   "source": [
    "### Now we can create a new column, for both train and test sets, to host the cleaned version of the tweets' text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "ShHEjdq_6Yhw",
    "outputId": "95cdfb6c-8fa8-47cf-e477-13a5152bba32"
   },
   "outputs": [],
   "source": [
    "df['text_clean'] = texts_new\n",
    "df_test['text_clean'] = texts_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_MUctvR6yfh"
   },
   "outputs": [],
   "source": [
    "df['text_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yspPBCOz68iW"
   },
   "outputs": [],
   "source": [
    "df_test['text_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qneu4ytj7C2M"
   },
   "outputs": [],
   "source": [
    "df['text_clean'][1:8].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnhUvSsk7a3E"
   },
   "source": [
    "### To assess the impact of text cleaning on tweet length, we will introduce a new column containing the length of the cleaned text. This will allow us to verify if the cleaning process removes a significant portion of the content or preserves the core message of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPQRWqVJ7NBc"
   },
   "outputs": [],
   "source": [
    "text_len = []\n",
    "for text in df.text_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    text_len.append(tweet_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "243_L5o17l0l"
   },
   "outputs": [],
   "source": [
    "df['text_len'] = text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrCY8bzT7tyh"
   },
   "outputs": [],
   "source": [
    "text_len_test = []\n",
    "for text in df_test.text_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    text_len_test.append(tweet_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKpISlj-76Pb"
   },
   "outputs": [],
   "source": [
    "df_test['text_len'] = text_len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saFP5wKG7-3g"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
    "plt.title('Training tweets with less than 10 words')\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLG1CoEa8JBg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.countplot(x='text_len', data=df_test[df_test['text_len']<10], palette='mako')\n",
    "plt.title('Test tweets with less than 10 words')\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4repcbvT3m8A"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['text_clean'].str.len())\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Text Length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX2UKVxc1o8u"
   },
   "source": [
    "# Data Cleaning Impact on Tweet Length\n",
    "Our cleaning process has resulted in a significant number of tweets with zero words. This is because some tweets originally consisted solely of mentions (e.g., \"@username\"), hashtags, and URLs, all of which were removed during cleaning. To ensure the remaining data is suitable for further analysis, we will exclude tweets with zero words and those containing less than five words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTEjdM4c8pUw"
   },
   "outputs": [],
   "source": [
    "print(f\" DF SHAPE: {df.shape}\")\n",
    "print(f\" DF TEST SHAPE: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y18Sfau48u-a"
   },
   "outputs": [],
   "source": [
    "df = df[df['text_len'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tchnbN7x8zpU"
   },
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['text_len'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_w_WKob85I1"
   },
   "outputs": [],
   "source": [
    "print(f\" DF SHAPE: {df.shape}\")\n",
    "print(f\" DF TEST SHAPE: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWS13hM69Lz6"
   },
   "source": [
    "# Enhancing Training Data Quality: Tokenizer Version Check\n",
    "\n",
    "In this step, we perform a more rigorous cleaning of the training data by ensuring compatibility with the tokenizer version used in the model. To achieve this, we begin by importing the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjRWBgkE8_Ze"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEiLsg2z9bXb"
   },
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df['text_clean'].values:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "\n",
    "max_len=np.max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5esNk8nF9tPx"
   },
   "outputs": [],
   "source": [
    "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL_fTNoK-Okt"
   },
   "source": [
    "### We will now analyze sentences exceeding 80 tokens after tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgvDqqR3-tiz"
   },
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for i,txt in enumerate(df['text_clean'].values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    if len(tokens)>80:\n",
    "        print(f\"INDEX: {i}, TEXT: {txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxCCUnNg_W7c"
   },
   "source": [
    "### The pre-processing stage will filter out sentences not identified as English for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDpZ6Fob_BmU"
   },
   "outputs": [],
   "source": [
    "df['token_lens'] = token_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQc4Jn1fAm2G"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='token_lens', ascending=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nmXIqiSAs2x"
   },
   "outputs": [],
   "source": [
    "df = df.iloc[12:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zf9-RYKTBDXc"
   },
   "source": [
    "### Data cleaning has been completed. To mitigate potential biases, the data will be shuffled, and the index will be reset before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av3NkSaKAw44"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSGbNPzcBqIw"
   },
   "source": [
    "# Enhanced Test Data Cleaning\n",
    "### Leveraging tokenization, we will conduct a more comprehensive data cleaning process on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9uXl54EBK_h"
   },
   "outputs": [],
   "source": [
    "token_lens_test = []\n",
    "\n",
    "for txt in df_test['text_clean'].values:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens_test.append(len(tokens))\n",
    "\n",
    "max_len=np.max(token_lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpICEOYuCknN"
   },
   "outputs": [],
   "source": [
    "print(f\"MAX TOKENIZED SENTENCE LENGTH: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bi2GD3KaCuoB"
   },
   "outputs": [],
   "source": [
    "token_lens_test = []\n",
    "\n",
    "for i,txt in enumerate(df_test['text_clean'].values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens_test.append(len(tokens))\n",
    "    if len(tokens)>80:\n",
    "        print(f\"INDEX: {i}, TEXT: {txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NFmTkssCzgw"
   },
   "outputs": [],
   "source": [
    "df_test['token_lens'] = token_lens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsThWV_aC5-x"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.sort_values(by='token_lens', ascending=False)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-9MmECZDGA-"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.iloc[5:]\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpsM9vjNDPpl"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3l_TFmvDxsW"
   },
   "source": [
    "# Analyzing Sentiment Labels\n",
    "We now turn our attention to the 'Sentiment' column, which contains the target labels for our sentiment classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zo12egyDdKy"
   },
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLl7VfNdE9wh"
   },
   "source": [
    "Our initial step involves encoding the categorical labels with numerical representations. Additionally, we will consolidate the emotional categories into three primary classes: positive, neutral, and negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyKnwr1PEcHF"
   },
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq-OHivDFI7I"
   },
   "outputs": [],
   "source": [
    "df_test['Sentiment'] = df_test['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WscpShXpFl39"
   },
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u79RQZzoGkQ3"
   },
   "source": [
    "Our analysis reveals a class imbalance within the data. To mitigate potential bias towards the majority classes, we will employ an oversampling technique on the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jS2ggucHktA"
   },
   "source": [
    "# Random Oversampling Technique for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-p24Eo8sFoOk"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "train_x, train_y = ros.fit_resample(np.array(df['text_clean']).reshape(-1, 1), np.array(df['Sentiment']).reshape(-1, 1));\n",
    "train_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text_clean', 'Sentiment']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3wuXQbiHsFx"
   },
   "outputs": [],
   "source": [
    "train_os['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3uG39l-ImeH"
   },
   "source": [
    "# Train - Validation - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntuSfU6pzmVn"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42  # make sure this matches your previous seed value\n",
    "\n",
    "# Assuming df is your original dataframe\n",
    "X = df['text_clean'].values.reshape(-1, 1)\n",
    "y = df['Sentiment'].values\n",
    "\n",
    "# Split into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "\n",
    "# Oversample the train+validation set\n",
    "oversampler = RandomOverSampler(random_state=seed)\n",
    "X_train_val_resampled, y_train_val_resampled = oversampler.fit_resample(X_train_val, y_train_val)\n",
    "\n",
    "# Split the resampled data into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val_resampled, y_train_val_resampled,\n",
    "                                                      test_size=0.1, stratify=y_train_val_resampled,\n",
    "                                                      random_state=seed)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_valid.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZcPAHsvJ1nu"
   },
   "source": [
    "# One Hot Encoding\n",
    "Our exploration of different encoding methods for the target variable revealed that one-hot encoding yielded superior accuracy compared to label encoding. Consequently, we will adopt one-hot encoding for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsXj7bYE2UAc"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of original dataset:\", df.shape)\n",
    "print(\"Shape of X after splitting:\", X_train.shape, X_test.shape)\n",
    "print(\"Shape of y after splitting:\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfUxoMgV68R4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Assume X_train, y_train are already defined\n",
    "\n",
    "# Print shapes of input data\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# After vectorization\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Reshape X_train to a 1D array of strings\n",
    "X_train_reshaped = X_train.ravel()  # Flatten the array\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train_reshaped) # Pass the 1D array of strings\n",
    "print(\"Shape of X_train_cv:\", X_train_cv.shape)\n",
    "\n",
    "# TF-IDF Transformation\n",
    "tf_transformer = TfidfTransformer(use_idf=True)\n",
    "X_train_tf = tf_transformer.fit_transform(X_train_cv)  # Use fit_transform instead of just transform\n",
    "print(\"Shape of X_train_tf:\", X_train_tf.shape)\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "print(\"Shape of y_train_le:\", y_train_le.shape)\n",
    "\n",
    "# Verify shapes match\n",
    "assert X_train_tf.shape[0] == y_train_le.shape[0], \"Mismatch in number of samples between features and labels\"\n",
    "\n",
    "# Now you can fit your model\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tf, y_train_le)\n",
    "print(\"Model fitted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRS1xgdS7G_W"
   },
   "outputs": [],
   "source": [
    "y_valid_le = le.transform(y_valid)\n",
    "y_test_le = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyx2o8v9MOxN"
   },
   "outputs": [],
   "source": [
    "print(f\"TRAINING DATA: {X_train.shape[0]}\\nVALIDATION DATA: {X_valid.shape[0]}\\nTESTING DATA: {X_test.shape[0]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxmGDcqzOe-A"
   },
   "source": [
    "# Evaluation Benchmark: Naive Bayes Classifier\n",
    "\n",
    "To establish a performance benchmark, we begin by implementing a Naive Bayes classifier. This simple yet effective model will serve as a baseline for comparison with the subsequent BERT-based approach. Prior to classification, tweets will be preprocessed using CountVectorizer for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L513hafSQf4U"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Assuming 'cv' is your CountVectorizer instance from previous cells\n",
    "X_test_cv = cv.transform(X_test.ravel())  # Vectorize X_test\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
    "X_train_tf = tf_transformer.transform(X_train_cv)\n",
    "X_test_tf = tf_transformer.transform(X_test_cv)  # Now this should work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqPYl8bGSZTw"
   },
   "source": [
    "Next, we will instantiate the Naive Bayes classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQna67vsSIIf"
   },
   "outputs": [],
   "source": [
    "nb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46WYWGdtSkHB"
   },
   "outputs": [],
   "source": [
    "nb_clf.fit(X_train_tf, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61EcanZaSx4Z"
   },
   "outputs": [],
   "source": [
    "nb_pred = nb_clf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK6PCqY1TROB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('\\tClassification Report for Naive Bayes:\\n\\n',classification_report(y_test_le,nb_pred, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQTBjp5VP9S"
   },
   "source": [
    "# BERT Sentiment Analysis\n",
    "Having completed the initial sentiment analysis with tokenized sentences, we now proceed to define a custom tokenizer function specifically designed for BERT. Subsequently, we will leverage the encode_plus method of the BERT tokenizer to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ueKeE2t-OqB"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Load the pre-trained BERT model (base-uncased) from Hugging Face Transformers\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the corresponding tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7Nbv5oN-n6a"
   },
   "outputs": [],
   "source": [
    "MAX_LEN=128\n",
    "def create_model(bert_model, max_len=MAX_LEN):\n",
    "    \"\"\"\n",
    "    Creates a sentiment analysis model using a pre-trained BERT model.\n",
    "\n",
    "    Args:\n",
    "        bert_model (transformers.TFModelForSequenceClassification): The pre-trained BERT model to use for sentiment classification.\n",
    "        max_len (int, optional): The maximum sequence length for input text. Defaults to MAX_LEN (defined elsewhere).\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The compiled sentiment analysis model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define optimizer, loss function, and accuracy metric\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # Create input layers for token IDs and attention masks\n",
    "    input_ids = tf.keras.Input(shape=(max_len,), dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(max_len,), dtype='int32')\n",
    "\n",
    "    # Extract token embeddings from the pre-trained BERT model\n",
    "    # Wrap the BERT model call in a Lambda layer to convert KerasTensors to TensorFlow Tensors\n",
    "    embeddings = tf.keras.layers.Lambda(lambda x: bert_model(x)[1])([input_ids, attention_masks])\n",
    "\n",
    "    # Add a Dense layer with softmax activation for multi-class classification (3 classes: Negative, Neutral, Positive)\n",
    "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(embeddings)\n",
    "\n",
    "    # Create the Keras model with inputs and outputs\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "\n",
    "    # Compile the model with optimizer, loss function, and accuracy metric\n",
    "    model.compile(opt, loss=loss, metrics=accuracy)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zr_7bkQAVyVo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = create_model(bert_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_igs1efOg4k"
   },
   "outputs": [],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIJKicu52twA",
    "outputId": "ff8ea7c6-9028-4015-923d-85b73725d643"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define constants\n",
    "max_length = 128\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        [t[0] for t in texts.tolist()],  # Extract the single string from each element\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize your data\n",
    "X_train_tokenized = tokenize_data(X_train)\n",
    "X_valid_tokenized = tokenize_data(X_valid)\n",
    "\n",
    "# Convert labels to categorical if not already done\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_valid_encoded = tf.keras.utils.to_categorical(y_valid, num_classes=num_classes)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train_encoded))\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(X_valid_tokenized), y_valid_encoded))\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Adjust callbacks\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Load the latest checkpoint\n",
    "latest_checkpoint = tf.train.latest_checkpoint('training_checkpoints')\n",
    "if latest_checkpoint:\n",
    "    print(f\"Restoring from checkpoint: {latest_checkpoint}\")\n",
    "    model.load_weights(latest_checkpoint)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ShcTxmZJzVBG",
    "outputId": "48aafd05-461d-40e8-babb-94f09d9265bf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "max_length = 128\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:0005}.ckpt\"\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        [t[0] for t in texts.tolist()],  # Extract the single string from each element\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize your data\n",
    "X_train_tokenized = tokenize_data(X_train)\n",
    "X_valid_tokenized = tokenize_data(X_valid)\n",
    "X_test_tokenized = tokenize_data(X_test)  # Add this for test data\n",
    "\n",
    "# Convert labels to categorical if not already done\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_valid_encoded = tf.keras.utils.to_categorical(y_valid, num_classes=num_classes)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)  # Add this for test data\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train_encoded))\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(X_valid_tokenized), y_valid_encoded))\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Adjust callbacks\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Load the latest checkpoint\n",
    "latest_checkpoint = tf.train.latest_checkpoint('training_checkpoints')\n",
    "if latest_checkpoint:\n",
    "    print(f\"Restoring from checkpoint: {latest_checkpoint}\")\n",
    "    model.load_weights(latest_checkpoint)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Predict using the trained model\n",
    "result_bert = model.predict(dict(X_test_tokenized))\n",
    "\n",
    "# Convert predicted probabilities to one-hot encoded predictions\n",
    "y_pred_probs = tf.nn.softmax(result_bert.logits, axis=-1).numpy()\n",
    "y_pred_bert = np.zeros_like(y_pred_probs)\n",
    "y_pred_bert[np.arange(len(y_pred_probs)), y_pred_probs.argmax(1)] = 1\n",
    "\n",
    "# Define the conf_matrix function\n",
    "def conf_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true.argmax(1), y_pred.argmax(1))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix(y_test_encoded, y_pred_bert, 'BERT Sentiment Analysis\\nConfusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAYf5GWrKemv"
   },
   "source": [
    "# BERT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rH4Sa68yTIXN",
    "outputId": "efd30eee-5dec-423e-8907-6de3aaf9e52c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the trained model\n",
    "result_bert = model.predict(dict(X_test_tokenized))\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_probs = tf.nn.softmax(result_bert.logits, axis=-1).numpy()\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert true labels to class labels\n",
    "y_true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=['Class 0', 'Class 1', 'Class 2']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7i7mTUDuTSz5"
   },
   "source": [
    "# RoBERTa for Sentiment Analysis\n",
    "Similar to BERT, we first import the RoBERTa tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "8dabb3fb998643e394d0fe034bc51113",
      "390f3336fd15439ab04651a9e539085c",
      "f0d0653cbc2d4bd4a3a8fe4bd643bdf8",
      "6604002e29334d7391fe0250ea8ebd90",
      "b9177fc2ef8c4419ab0762859f11cc98",
      "06644273928640b0869d56460d3daafe",
      "6772a282be8341a29e4c6b9fa532d326",
      "b61aced17dc2431a9d492cdac44a8bfa",
      "0bd2c9c20e6d4715b115845c4b514e6d",
      "19f61416014942f28778bb3d7e4ec6ff",
      "176e62ab6548492991c4adc50b8dc388",
      "bbbb46c6a0a548e4a2b5fb2f8eced29e",
      "4ffa84dd77684c11974f1c94382c46ce",
      "e3afeb76ff5947d8b4ab268d1cba9eaf",
      "5f7b6793fb97472791fd02b437b1efc8",
      "9483a4f298e5458a8600078985424a6b",
      "23a95e85db8044928398ed5383754d6f",
      "e7e09e9fe7174715ad46adca5ef8e66e",
      "d6de8709f86b49fe90ae6bd02f28c694",
      "89089f3cd97242c797f3eb1731b5eaa9",
      "36dedfe82d59421c905c125fa6984ab6",
      "dcc36611ac2b4a35aff9ce4c4e0e7a56",
      "77f62ec3393546489bcffcaee3b0650e",
      "ee80fbb540e94a418af54b6551f6fccb",
      "cfed2e67770a4926bc1ed1729b76bbe6",
      "c4b2dd83765e41018e53a28e12dd00ce",
      "efb0d1c5442f4921a38d085fd6a00e8b",
      "8ad7790ed19b4da698dae281c83cccd8",
      "0355ca9dc1bb481497a970f5fe436bdf",
      "6e76e623702b48d0ab9dc92f7dfb6a71",
      "c67612a285b049859f7ecd66195dce0d",
      "075464c036f74b17b0681847209abd71",
      "d0fe0eb7ba2a42f3b29814121bc5a17c",
      "34d640a1194947ea9bbdf6d5228d0d54",
      "512cbfff450a443aa33fd8d338226f27",
      "a7220c97314848cb8693bed63938820f",
      "1e0a11228b5a440db856983ea7832d1f",
      "4089171ecf7c4c28a63a968d1adcd978",
      "5f6fb487127143f1acad2778bccd3448",
      "a57583f40c004c308cd02f140712dc40",
      "77d8f599238645ad808d42b41e3b070a",
      "6dcaf4c332a04dcb8ea3799b0ec93242",
      "943d83ab2b0c406e80011a08c11b0615",
      "da40cb611aec4c518d0a16e700f922c7",
      "c892fe8c52374d6f82127f30de84fe94",
      "fb7739812db24cadac2c2387fff4933f",
      "2410bbbe86db4aa0a62dfb6f47d1638f",
      "a18ff63e935a45ce83e15e2cf441039f",
      "01655a02a8d74586b2471acc42e6a2b3",
      "acef2e59d9494b7d91dd95bf8e861a81",
      "540b6e9356644580b3e18c19483cdab9",
      "7e4642546460463a97415474c22ec00e",
      "c353b427108d4f93b255fe062cad18e3",
      "5ef4728ec2c64ee5a5f9a811dd14376c",
      "61cf3b87ea4b41229ce282f2829ed3df"
     ]
    },
    "id": "_Qh_9buBTriQ",
    "outputId": "4eeb222a-8a29-4034-fd34-b17e02c4e7cb"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained RoBERTa tokenizer\n",
    "tokenizer_roberta = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P2BPjJ_RNBVt",
    "outputId": "b8483137-42b0-476d-91a4-ec8fe56a06d7"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define constants\n",
    "max_length = 128\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Load RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Function to clean and flatten the data\n",
    "def preprocess_data(data):\n",
    "    if isinstance(data, list) and isinstance(data[0], list):\n",
    "        data = [item[0] for item in data]\n",
    "    # Remove surrounding brackets and quotes if present\n",
    "    data = [item.strip(\"[]'\") for item in data]\n",
    "    return data\n",
    "\n",
    "# Convert and preprocess your data\n",
    "X_train = preprocess_data(X_train)\n",
    "X_valid = preprocess_data(X_valid)\n",
    "X_test = preprocess_data(X_test)\n",
    "\n",
    "# Print out the first few elements to check\n",
    "print(\"First few elements of X_train:\", X_train[:5])\n",
    "print(\"First few elements of X_valid:\", X_valid[:5])\n",
    "print(\"First few elements of X_test:\", X_test[:5])\n",
    "\n",
    "# Tokenize the input data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize your data\n",
    "X_train_tokenized = tokenize_data(X_train)\n",
    "X_valid_tokenized = tokenize_data(X_valid)\n",
    "X_test_tokenized = tokenize_data(X_test)  # Add this for test data\n",
    "\n",
    "# Convert labels to categorical if not already done\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_valid_encoded = tf.keras.utils.to_categorical(y_valid, num_classes=num_classes)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)  # Add this for test data\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train_encoded))\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(X_valid_tokenized), y_valid_encoded))\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "# Load pre-trained RoBERTa model\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_classes)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Adjust callbacks\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Predict using the trained model\n",
    "result_roberta = model.predict(dict(X_test_tokenized))\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_probs = tf.nn.softmax(result_roberta.logits, axis=-1).numpy()\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert true labels to class labels\n",
    "y_true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Define the conf_matrix function\n",
    "def conf_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "conf_matrix(y_true_labels, y_pred_labels, 'RoBERTa Sentiment Analysis\\nConfusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xwr2yXTtm6l"
   },
   "source": [
    "# RoBERTa Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS6ePAM16mAN",
    "outputId": "6dff746a-30ce-4889-c74b-5adaf9497e7b"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "\n",
    "\n",
    "# Define constants\n",
    "max_length = 128\n",
    "num_classes = 3\n",
    "\n",
    "# Load the pre-trained RoBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_classes)\n",
    "\n",
    "\n",
    "# Tokenize test data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        texts,  # Assuming texts is a list of strings\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize your test data\n",
    "X_test_tokenized = tokenize_data(X_test)\n",
    "\n",
    "# Predict using the trained model\n",
    "def predict(model, X_test_tokenized):\n",
    "    predictions = model.predict(dict(X_test_tokenized))\n",
    "    return tf.argmax(predictions.logits, axis=-1).numpy()\n",
    "\n",
    "y_pred = predict(model, X_test_tokenized)\n",
    "\n",
    "# Generate classification report\n",
    "def generate_classification_report(y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(num_classes)], digits=4)\n",
    "\n",
    "# Print classification report\n",
    "print(generate_classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AahsFuAMBwBB",
    "outputId": "3fa54512-c95b-4a06-a9a5-cd0bef02dce6"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define constants\n",
    "max_length = 128\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Load the pre-trained RoBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_classes)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        texts,  # Assuming texts is a list of strings\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize your training, validation, and test data\n",
    "X_train_tokenized = tokenize_data(X_train)\n",
    "X_valid_tokenized = tokenize_data(X_valid)\n",
    "X_test_tokenized = tokenize_data(X_test)\n",
    "\n",
    "# Convert labels to categorical if not already done\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_valid_encoded = tf.keras.utils.to_categorical(y_valid, num_classes=num_classes)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train_encoded)).shuffle(len(X_train)).batch(batch_size)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(X_valid_tokenized), y_valid_encoded)).batch(batch_size)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Load the latest checkpoint if exists\n",
    "latest_checkpoint = tf.train.latest_checkpoint('training_checkpoints')\n",
    "if latest_checkpoint:\n",
    "    print(f\"Restoring from checkpoint: {latest_checkpoint}\")\n",
    "    model.load_weights(latest_checkpoint)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Predict using the trained model\n",
    "def predict(model, X_test_tokenized):\n",
    "    predictions = model.predict(dict(X_test_tokenized))\n",
    "    return tf.argmax(predictions.logits, axis=-1).numpy()\n",
    "\n",
    "y_pred = predict(model, X_test_tokenized)\n",
    "\n",
    "# Generate classification report\n",
    "def generate_classification_report(y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(num_classes)], digits=4)\n",
    "\n",
    "# Print classification report\n",
    "print(generate_classification_report(np.argmax(y_test_encoded, axis=1), y_pred))\n",
    "\n",
    "# Generate and plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(np.argmax(y_test_encoded, axis=1), y_pred, [f'Class {i}' for i in range(num_classes)])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01655a02a8d74586b2471acc42e6a2b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0355ca9dc1bb481497a970f5fe436bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06644273928640b0869d56460d3daafe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "075464c036f74b17b0681847209abd71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bd2c9c20e6d4715b115845c4b514e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "176e62ab6548492991c4adc50b8dc388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19f61416014942f28778bb3d7e4ec6ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0a11228b5a440db856983ea7832d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_943d83ab2b0c406e80011a08c11b0615",
      "placeholder": "​",
      "style": "IPY_MODEL_da40cb611aec4c518d0a16e700f922c7",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 6.13MB/s]"
     }
    },
    "23a95e85db8044928398ed5383754d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2410bbbe86db4aa0a62dfb6f47d1638f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e4642546460463a97415474c22ec00e",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c353b427108d4f93b255fe062cad18e3",
      "value": 481
     }
    },
    "34d640a1194947ea9bbdf6d5228d0d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_512cbfff450a443aa33fd8d338226f27",
       "IPY_MODEL_a7220c97314848cb8693bed63938820f",
       "IPY_MODEL_1e0a11228b5a440db856983ea7832d1f"
      ],
      "layout": "IPY_MODEL_4089171ecf7c4c28a63a968d1adcd978"
     }
    },
    "36dedfe82d59421c905c125fa6984ab6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "390f3336fd15439ab04651a9e539085c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06644273928640b0869d56460d3daafe",
      "placeholder": "​",
      "style": "IPY_MODEL_6772a282be8341a29e4c6b9fa532d326",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4089171ecf7c4c28a63a968d1adcd978": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ffa84dd77684c11974f1c94382c46ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23a95e85db8044928398ed5383754d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_e7e09e9fe7174715ad46adca5ef8e66e",
      "value": "vocab.json: 100%"
     }
    },
    "512cbfff450a443aa33fd8d338226f27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f6fb487127143f1acad2778bccd3448",
      "placeholder": "​",
      "style": "IPY_MODEL_a57583f40c004c308cd02f140712dc40",
      "value": "tokenizer.json: 100%"
     }
    },
    "540b6e9356644580b3e18c19483cdab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ef4728ec2c64ee5a5f9a811dd14376c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f6fb487127143f1acad2778bccd3448": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f7b6793fb97472791fd02b437b1efc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36dedfe82d59421c905c125fa6984ab6",
      "placeholder": "​",
      "style": "IPY_MODEL_dcc36611ac2b4a35aff9ce4c4e0e7a56",
      "value": " 899k/899k [00:00&lt;00:00, 4.00MB/s]"
     }
    },
    "61cf3b87ea4b41229ce282f2829ed3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6604002e29334d7391fe0250ea8ebd90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19f61416014942f28778bb3d7e4ec6ff",
      "placeholder": "​",
      "style": "IPY_MODEL_176e62ab6548492991c4adc50b8dc388",
      "value": " 25.0/25.0 [00:00&lt;00:00, 2.39kB/s]"
     }
    },
    "6772a282be8341a29e4c6b9fa532d326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dcaf4c332a04dcb8ea3799b0ec93242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e76e623702b48d0ab9dc92f7dfb6a71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d8f599238645ad808d42b41e3b070a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77f62ec3393546489bcffcaee3b0650e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee80fbb540e94a418af54b6551f6fccb",
       "IPY_MODEL_cfed2e67770a4926bc1ed1729b76bbe6",
       "IPY_MODEL_c4b2dd83765e41018e53a28e12dd00ce"
      ],
      "layout": "IPY_MODEL_efb0d1c5442f4921a38d085fd6a00e8b"
     }
    },
    "7e4642546460463a97415474c22ec00e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89089f3cd97242c797f3eb1731b5eaa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ad7790ed19b4da698dae281c83cccd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dabb3fb998643e394d0fe034bc51113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_390f3336fd15439ab04651a9e539085c",
       "IPY_MODEL_f0d0653cbc2d4bd4a3a8fe4bd643bdf8",
       "IPY_MODEL_6604002e29334d7391fe0250ea8ebd90"
      ],
      "layout": "IPY_MODEL_b9177fc2ef8c4419ab0762859f11cc98"
     }
    },
    "943d83ab2b0c406e80011a08c11b0615": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9483a4f298e5458a8600078985424a6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18ff63e935a45ce83e15e2cf441039f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ef4728ec2c64ee5a5f9a811dd14376c",
      "placeholder": "​",
      "style": "IPY_MODEL_61cf3b87ea4b41229ce282f2829ed3df",
      "value": " 481/481 [00:00&lt;00:00, 43.4kB/s]"
     }
    },
    "a57583f40c004c308cd02f140712dc40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7220c97314848cb8693bed63938820f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77d8f599238645ad808d42b41e3b070a",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6dcaf4c332a04dcb8ea3799b0ec93242",
      "value": 1355863
     }
    },
    "acef2e59d9494b7d91dd95bf8e861a81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b61aced17dc2431a9d492cdac44a8bfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9177fc2ef8c4419ab0762859f11cc98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbbb46c6a0a548e4a2b5fb2f8eced29e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ffa84dd77684c11974f1c94382c46ce",
       "IPY_MODEL_e3afeb76ff5947d8b4ab268d1cba9eaf",
       "IPY_MODEL_5f7b6793fb97472791fd02b437b1efc8"
      ],
      "layout": "IPY_MODEL_9483a4f298e5458a8600078985424a6b"
     }
    },
    "c353b427108d4f93b255fe062cad18e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c4b2dd83765e41018e53a28e12dd00ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_075464c036f74b17b0681847209abd71",
      "placeholder": "​",
      "style": "IPY_MODEL_d0fe0eb7ba2a42f3b29814121bc5a17c",
      "value": " 456k/456k [00:00&lt;00:00, 2.11MB/s]"
     }
    },
    "c67612a285b049859f7ecd66195dce0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c892fe8c52374d6f82127f30de84fe94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb7739812db24cadac2c2387fff4933f",
       "IPY_MODEL_2410bbbe86db4aa0a62dfb6f47d1638f",
       "IPY_MODEL_a18ff63e935a45ce83e15e2cf441039f"
      ],
      "layout": "IPY_MODEL_01655a02a8d74586b2471acc42e6a2b3"
     }
    },
    "cfed2e67770a4926bc1ed1729b76bbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e76e623702b48d0ab9dc92f7dfb6a71",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c67612a285b049859f7ecd66195dce0d",
      "value": 456318
     }
    },
    "d0fe0eb7ba2a42f3b29814121bc5a17c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6de8709f86b49fe90ae6bd02f28c694": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da40cb611aec4c518d0a16e700f922c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcc36611ac2b4a35aff9ce4c4e0e7a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3afeb76ff5947d8b4ab268d1cba9eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6de8709f86b49fe90ae6bd02f28c694",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89089f3cd97242c797f3eb1731b5eaa9",
      "value": 898823
     }
    },
    "e7e09e9fe7174715ad46adca5ef8e66e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee80fbb540e94a418af54b6551f6fccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ad7790ed19b4da698dae281c83cccd8",
      "placeholder": "​",
      "style": "IPY_MODEL_0355ca9dc1bb481497a970f5fe436bdf",
      "value": "merges.txt: 100%"
     }
    },
    "efb0d1c5442f4921a38d085fd6a00e8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0d0653cbc2d4bd4a3a8fe4bd643bdf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b61aced17dc2431a9d492cdac44a8bfa",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bd2c9c20e6d4715b115845c4b514e6d",
      "value": 25
     }
    },
    "fb7739812db24cadac2c2387fff4933f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acef2e59d9494b7d91dd95bf8e861a81",
      "placeholder": "​",
      "style": "IPY_MODEL_540b6e9356644580b3e18c19483cdab9",
      "value": "config.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
